# -*- coding: utf-8 -*-
"""DL_A4_Q1(final).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-KuOVSt-hBz2xLkRHXYVM5hXkWnsXBHX
"""

# import libraries
import os
import torch
from torch.utils.data import Dataset
from PIL import Image
import pandas as pd
from torchvision.transforms import transforms
import torchvision
import numpy as np
import json
import cv2
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
from sklearn.metrics import f1_score, confusion_matrix
from sklearn.metrics import precision_recall_fscore_support
from sklearn import preprocessing
from tqdm.notebook import tqdm

from google.colab import drive
drive.mount('/content/drive')

# class to load image
class PNGDataset(Dataset):
    def __init__(self, root_dir, df, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.filenames = os.listdir(root_dir)
        self.df = df

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        filename = self.filenames[idx]
        file_name = str(self.df['id'][idx])
        if len(file_name) == 4:
            file_name = '0'+file_name
        img_path = os.path.join(self.root_dir, file_name+'.png')
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, self.df['label'][idx]

# get train labels with images
train_labels = pd.read_json('/content/drive/MyDrive/DL/DL Assignments/A4/hateful_memes/train.jsonl', lines=True)
train_labels

# get val labels with images
val_labels = pd.read_json(path_or_buf='/content/drive/MyDrive/DL/DL Assignments/A4/hateful_memes/dev_seen.jsonl', lines=True)
val_labels

# get test labels with images
test_labels = pd.read_json(path_or_buf='/content/drive/MyDrive/DL/DL Assignments/A4/hateful_memes/test_seen.jsonl', lines=True)
test_labels

# apply necessary transformations like resize and normalize
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((256,256)),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])
# split into train, test and val set
train_dataset = PNGDataset('/content/drive/MyDrive/DL/DL Assignments/A4/hateful_memes/img', train_labels)
val_dataset = PNGDataset('/content/drive/MyDrive/DL/DL Assignments/A4/hateful_memes/img', val_labels)
test_dataset = PNGDataset('/content/drive/MyDrive/DL/DL Assignments/A4/hateful_memes/img', test_labels)

plt.imshow(train_dataset[8495][0])

train_dataset[8495][1]

# class that applies transformations to images
class ImageDataset():
    def __init__(self, data,transform=None, target_transform=None):
        self.data=data
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        image = self.data[idx][0]
        label = self.data[idx][1]
        if self.transform is not None:
            image = self.transform(image)
        return image, label

batch_size = 256
# defining data loaders
train_loader = torch.utils.data.DataLoader(ImageDataset(train_dataset,transform=transform), batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(ImageDataset(val_dataset,transform=transform), batch_size)
test_loader = torch.utils.data.DataLoader(ImageDataset(test_dataset,transform=transform), batch_size*2)

def get_default_device():
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')
    
def to_device(data, device):
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

# data loader class
class DeviceDataLoader():
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        
    def __iter__(self):
        for b in self.dl: 
            yield to_device(b, self.device)

    def __len__(self):
        return len(self.dl)

# using pre trained resnet model
resnet18 = torchvision.models.resnet18(pretrained=True)
resnet18

# change fully conneced layer to 2 nodes
resnet18.fc = nn.Linear(in_features=512, out_features=2)

# defining loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet18.parameters(), lr=0.0001)

device = get_default_device()
device

# load data using data loaders
train_loader = DeviceDataLoader(train_loader, device)
val_loader = DeviceDataLoader(val_loader, device)
test_loader=DeviceDataLoader(test_loader,device)
to_device(resnet18, device);
# resnet18=resnet18.to('device')

# function to compute results on validation set
def validation(model, validateloader, criterion):
    
    val_loss = 0
    accuracy = 0
    correct = 0
    total = 0
    count=0

    for images, labels in iter(validateloader):
        outputs = model(images)
        val_loss += criterion(outputs, labels).item()
        count+=1
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    
    return val_loss, accuracy, count

# func to compute accuracy
def acc(ouputs,labels):
    total=0
    accuracy = 0
    correct=0
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    
    return accuracy

total_loss_train = []
total_loss_validation = []
taccuracy = []
vaccuracy = []
# train loop
for epoch in range(10):

    print(epoch + 1)
    batch_loss_train=0
    num_batches = 0
    running_loss = 0.0
    temp_acc = 0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data
        optimizer.zero_grad()
        
        outputs = resnet18(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        temp_acc+=acc(outputs,labels)
        batch_loss_train+=loss.item()
        running_loss = loss.item()
        num_batches+=1
      
    taccuracy.append(temp_acc/num_batches)    
    batch_loss_train/=num_batches
    print("Training Loss ",batch_loss_train)

    total_loss_train.append(batch_loss_train)
    with torch.no_grad():
      validation_loss, accuracy,cnt = validation(resnet18, val_loader, criterion)
      vaccuracy.append(accuracy)
      total_loss_validation += [validation_loss/cnt]
      print("Validation loss is ",validation_loss/cnt)
      print("Validation Acc is ", accuracy)
    

print('Finished Training')

# save the model
torch.save(resnet18.state_dict(),"model.pth")

taccuracy

# Plot the training and validation loss
plt.plot(total_loss_train, label='Training Loss')
plt.plot(total_loss_validation, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Plot the training and validation loss
plt.plot(taccuracy, label='Training Accuracy')
plt.plot(vaccuracy, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

state_dict = torch.load("model.pth")
resnet18.load_state_dict(state_dict)

# measure test accurancy
correct = 0
total = 0
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        outputs = resnet18(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Test Accuracy :- {100 * correct // total} %')

# Initialize lists to store labels and predictions
labels = []
predictions = []

# Iterate over test set and make predictions
with torch.no_grad():
    for images, targets in test_loader:
        outputs = resnet18(images)
        _, preds = torch.max(outputs, 1)
        labels += targets.tolist()
        predictions += preds.tolist()

# Calculate overall precision, recall, and F1 score
precision, recall, f1_score, _ = precision_recall_fscore_support(labels, predictions, average='macro')

print(f'Overall Precision: {precision:.4f}')
print(f'Overall Recall: {recall:.4f}')
print(f'Overall F1 Score: {f1_score:.4f}')

# Calculate class-wise precision, recall, and F1 score
precision, recall, f1_score, support = precision_recall_fscore_support(labels, predictions)

for i in range(2):
    print(f'Class {i} - Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1 Score: {f1_score[i]:.4f}')

import pickle
with open('parrot.pkl', 'rb') as f:
  compare_labels = pickle.load(f)

state_dict = torch.load("/content/drive/MyDrive/DL/DL Assignments/A4/Q1/model.pth",map_location=torch.device('cpu'))
resnet18.load_state_dict(state_dict)

# get test labels with images
# test_labels = pd.read_json(path_or_buf='/content/drive/MyDrive/hateful_memes/test_seen.jsonl', lines=True)
# l1 = list(test_labels[test_labels.label == 1][:50].index.values)
# l2 = list(test_labels[test_labels.label == 0][:50].index.values)

import pickle
with open('parrot.pkl', 'rb') as f:
  compare_labels = pickle.load(f)
# apply necessary transformations like resize and normalize
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((256,256)),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])
# split into train, test and val se
compare_dataset = PNGDataset('/content/drive/MyDrive/DL/DL Assignments/A4/hateful_memes/img', compare_labels)

# defining data loaders
compare_loader = torch.utils.data.DataLoader(ImageDataset(compare_dataset,transform=transform), 100)

get_graph_node_names(resnet18)

from torchvision.models.feature_extraction import create_feature_extractor
from torchvision.models.feature_extraction import get_graph_node_names
import seaborn as sns
from matplotlib.colors import ListedColormap
from sklearn.manifold import TSNE

# train_loader = 
count=0
with torch.no_grad() :
    for i,j in compare_loader:
      X = (create_feature_extractor(resnet18.to('cpu'),{"avgpool":'avgpool'})(i.to('cpu'))['avgpool']).detach().numpy()
      X = X.reshape(100,-1)
      X_embedded = TSNE(n_components=2, learning_rate='auto',init='pca', perplexity=3).fit_transform(X)
      x1= []
      y1 = []
      for i in X_embedded:
        x1.append(i[0])
        y1.append(i[1])
      print(len(j),len(x1),len(y1))
      sns.scatterplot(x=x1,y=y1,hue=j,palette="deep")
      
cmap = ListedColormap(sns.color_palette("deep", 256).as_hex())